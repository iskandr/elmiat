{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5787df2c",
   "metadata": {},
   "source": [
    "**Sources** \n",
    "* HuggingFace SpeechT5 tutorial to combine ASR and TTS (https://huggingface.co/blog/speecht5)\n",
    "* HuggingFace LLM tutorial: https://huggingface.co/docs/transformers/main/llm_tutorial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b245567",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch\n",
    "!pip install -q sentencepiece\n",
    "!pip install -q torchaudio \n",
    "!pip install -q -U transformers\n",
    "!pip install -q soundfile\n",
    "!pip install -q bitsandbytes\n",
    "!pip install -q accelerate \n",
    "\n",
    "# there's probably a better library for playing audio \n",
    "!pip install -q simpleaudio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a31da72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n",
      "Configuration already exists at /Users/iskander/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    }
   ],
   "source": [
    "!python -c \"from accelerate.utils import write_basic_config; write_basic_config(mixed_precision='fp16')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82060322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2086-149220-0033.wav\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898d727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an example sound file\n",
    "\n",
    "import soundfile as sf\n",
    "# returns a tuple of (NumPy array of the waveform, sampling rate)\n",
    "input_sound_tuple = sf.read(\"../data/2086-149220-0033.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9d4c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00000000e+00, 9.15527344e-05, 9.15527344e-05, ...,\n",
       "        1.22070312e-04, 1.22070312e-04, 1.22070312e-04]),\n",
       " 16000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sound_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b752bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sound, sampling_rate = input_sound_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b081287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/speecht5_asr were not used when initializing SpeechT5ForSpeechToText: ['speecht5.encoder.prenet.pos_conv_embed.conv.weight_g', 'speecht5.encoder.prenet.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing SpeechT5ForSpeechToText from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing SpeechT5ForSpeechToText from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of SpeechT5ForSpeechToText were not initialized from the model checkpoint at microsoft/speecht5_asr and are newly initialized: ['speecht5.encoder.prenet.pos_conv_embed.conv.parametrizations.weight.original0', 'speecht5.encoder.prenet.pos_conv_embed.conv.parametrizations.weight.original1', 'speecht5.encoder.prenet.pos_sinusoidal_embed.weights']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "asr = pipeline(task=\"automatic-speech-recognition\", model=\"microsoft/speecht5_asr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89eee4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get back a text transcription from the sound\n",
    "asr_result = asr(input_sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06b5ac7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"well i don't wish to see it any more observed febric turning away her eyes it is certainly very like the old portrait\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's dictionary with a single field called 'text'\n",
    "asr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b19d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = asr_result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99bef7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "torch.set_default_device(\"mps\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1_5\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1_5\", trust_remote_code=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cf344d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNarrator: Lady Macbeth has been trapped within the body of cypress tree \\nwithin the Everglades by otherworldly witches. She was cursed into this fate because of her attempts to destroy \\nthe Everglades ecosystem and kill all of the trees it contained. She is now at peace and has become spooky, mystical, poetrically enchanting. \\nVisitor: Are ye Lady Macbeth?\\nLady Macbeth: Ich usede bihofþe bæ hē̆r\\nVisitor: How have you come to such a state?\\nLady Macbeth: For my crimes, the blood of groves cries up from the muck. \\nVisitor: well i don't wish to see it any more observed febric turning away her eyes it is certainly very like the old portrait\\n Lady Macbeth:\""
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give the LLM some instructions and then feed it the text which we recognized from audio\n",
    "\n",
    "prompt_prefix = \"\"\"\n",
    "Narrator: Lady Macbeth has been trapped within the body of cypress tree \n",
    "within the Everglades by otherworldly witches. She was cursed into this fate because of her attempts to destroy \n",
    "the Everglades ecosystem and kill all of the trees it contained. She is now at peace and has become spooky, mystical, poetrically enchanting. \n",
    "Visitor: Are ye Lady Macbeth?\n",
    "Lady Macbeth: Ich usede bihofþe bæ hē̆r\n",
    "Visitor: How have you come to such a state?\n",
    "Lady Macbeth: For my crimes, the blood of groves cries up from the muck. \n",
    "Visitor: \"\"\"\n",
    "prompt = prompt_prefix + input_text + \"\\n Lady Macbeth:\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6530830a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  198, 45750,  1352,    25, 11182,  4100,    65,  2788,   468,   587,\n",
       "         13640,  1626,   262,  1767,   286,  3075,  8439,  5509,   220,   198,\n",
       "         33479,   262, 10776,  4743,  2367,   416,   584, 49366, 34773,    13,\n",
       "          1375,   373, 25155,   656,   428, 10030,   780,   286,   607,  6370,\n",
       "           284,  4117,   220,   198,  1169, 10776,  4743,  2367, 13187,   290,\n",
       "          1494,   477,   286,   262,  7150,   340,  7763,    13,  1375,   318,\n",
       "           783,   379,  4167,   290,   468,  1716,   599, 29655,    11, 29746,\n",
       "            11, 21810,    81,  1146, 23260,   278,    13,   220,   198, 15854,\n",
       "          2072,    25,  4231,  9838, 11182,  4100,    65,  2788,    30,   198,\n",
       "         38887,  4100,    65,  2788,    25, 26364,   973,    68,  3182, 39891,\n",
       "           127,   122,    68,   275, 21241,   289, 27092,   136,   228,    81,\n",
       "           198, 15854,  2072,    25,  1374,   423,   345,  1282,   284,   884,\n",
       "           257,  1181,    30,   198, 38887,  4100,    65,  2788,    25,  1114,\n",
       "           616,  6741,    11,   262,  2910,   286,  7128,  1158, 24691,   510,\n",
       "           422,   262,   285,  1347,    13,   220,   198, 15854,  2072,    25,\n",
       "           880,  1312,   836,   470,  4601,   284,   766,   340,   597,   517,\n",
       "          6515,   730,    65,  1173,  6225,  1497,   607,  2951,   340,   318,\n",
       "          3729,   845,   588,   262,  1468, 18560,   198, 11182,  4100,    65,\n",
       "          2788,    25]], device='mps:0')}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create token IDs for the prompt\n",
    "llm_inputs = tokenizer(prompt, return_tensors=\"pt\", return_attention_mask=False);\n",
    "llm_inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c6004cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  198, 45750,  1352,    25, 11182,  4100,    65,  2788,   468,   587,\n",
       "         13640,  1626,   262,  1767,   286,  3075,  8439,  5509,   220,   198,\n",
       "         33479,   262, 10776,  4743,  2367,   416,   584, 49366, 34773,    13,\n",
       "          1375,   373, 25155,   656,   428, 10030,   780,   286,   607,  6370,\n",
       "           284,  4117,   220,   198,  1169, 10776,  4743,  2367, 13187,   290,\n",
       "          1494,   477,   286,   262,  7150,   340,  7763,    13,  1375,   318,\n",
       "           783,   379,  4167,   290,   468,  1716,   599, 29655,    11, 29746,\n",
       "            11, 21810,    81,  1146, 23260,   278,    13,   220,   198, 15854,\n",
       "          2072,    25,  4231,  9838, 11182,  4100,    65,  2788,    30,   198,\n",
       "         38887,  4100,    65,  2788,    25, 26364,   973,    68,  3182, 39891,\n",
       "           127,   122,    68,   275, 21241,   289, 27092,   136,   228,    81,\n",
       "           198, 15854,  2072,    25,  1374,   423,   345,  1282,   284,   884,\n",
       "           257,  1181,    30,   198, 38887,  4100,    65,  2788,    25,  1114,\n",
       "           616,  6741,    11,   262,  2910,   286,  7128,  1158, 24691,   510,\n",
       "           422,   262,   285,  1347,    13,   220,   198, 15854,  2072,    25,\n",
       "           880,  1312,   836,   470,  4601,   284,   766,   340,   597,   517,\n",
       "          6515,   730,    65,  1173,  6225,  1497,   607,  2951,   340,   318,\n",
       "          3729,   845,   588,   262,  1468, 18560,   198, 11182,  4100,    65,\n",
       "          2788,    25,  1002,   345,   765,   284,   766,   340,   766,   340,\n",
       "           351,   534,   898,  2951,    11,   220,   198,   464,   886,    13,\n",
       "           198, 33221,    25,  5934,    83, 17500, 11081,   355,   257, 23584,\n",
       "          2891,    13,   198,   198, 20418,    83, 17500, 13920,   460,   307,\n",
       "           973,   284, 10716, 10712,  8405,   510,   284,   262,  4778,   290,\n",
       "           460,   307,  9569,   416,   257,  8776, 27104,  1258,  1349,  7451,\n",
       "            11,   393,   416,   257,  3830,  6259,  1141,   257,  8027,  3187,\n",
       "           284,   257,  2055,  1535,  3641,    13,  2312,  4410,   460,  1249,\n",
       "           329,  2068,   290,  7187,  3781,   286,  1728,  3315,  3403,   290,\n",
       "         10040,    13,   198, 24361,    25,  2141, 27104, 17500, 13920,   761,\n",
       "           257,  2041,  3047,  1430,   284,  8076,    30,   198, 33706,    25,\n",
       "          3363,    11]], device='mps:0')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figured this out manually for phi-1.5\n",
    "system_prompt_length = 91\n",
    "min_extra_tokens = 10\n",
    "max_extra_tokens = 200\n",
    "# sample from the LLM\n",
    "output_token_ids = model.generate(\n",
    "    **llm_inputs, \n",
    "    min_length = len(llm_inputs) + system_prompt_length + min_extra_tokens,\n",
    "    max_length=len(llm_inputs) + system_prompt_length + max_extra_tokens,\n",
    "    do_sample=True);\n",
    "output_token_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c2a03b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNarrator: Lady Macbeth has been trapped within the body of cypress tree \\nwithin the Everglades by otherworldly witches. She was cursed into this fate because of her attempts to destroy \\nthe Everglades ecosystem and kill all of the trees it contained. She is now at peace and has become spooky, mystical, poetrically enchanting. \\nVisitor: Are ye Lady Macbeth?\\nLady Macbeth: Ich usede bihofþe bæ hē̆r\\nVisitor: How have you come to such a state?\\nLady Macbeth: For my crimes, the blood of groves cries up from the muck. \\nVisitor: well i don't wish to see it any more observed febric turning away her eyes it is certainly very like the old portrait\\n Lady Macbeth: If you want to see it see it with your own eyes, \\nThe end.\\nTopic: Cytoscopy as a diagnostic tool.\\n\\nCytoscopes can be used to examine tissue samples up to the cells and can be viewed by a trained cytotechnologist, or by a layperson during a routine visit to a community health center. These devices can allow for quick and accurate analysis of certain medical conditions and diseases.\\nQuestion: Do cytoscopes need a special training program to operate?\\nAnswer: Yes,\""
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_text = tokenizer.batch_decode(output_token_ids)[0];\n",
    "output_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "8914e4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re.compile(\"Lady Macbeth: [a-zA-Z ,;:'-]+\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'If you want to see it see it with your own eyes, '"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "lady_macbeth = \"Lady Macbeth: \"\n",
    "regex = re.compile(lady_macbeth + \"[a-zA-Z ,;:'-]+\"); print(regex)\n",
    "longest_llm_output = max(regex.findall(output_text)[2:], key=len)[len(lady_macbeth):];\n",
    "longest_llm_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f164b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech\n",
    "\n",
    "# the text-to-speech model has two parts: a tokenizer/processor which turns the character stream into \n",
    "# a matrix of token IDs and an actual speech synthesizer\n",
    "tts_processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "tts_model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed89be94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 4, 20,  5, 15, 15,  4, 10,  4, 14,  8,  9, 31,  6,  4, 20, 10, 12, 11,\n",
       "          4,  6,  8,  4, 12,  5,  5,  4, 10,  6,  4,  7,  9, 22,  4, 18,  8, 13,\n",
       "          5,  4,  8, 25, 12,  5, 13, 27,  5, 14,  4, 19,  5, 25, 13, 10, 17,  4,\n",
       "          6, 16, 13,  9, 10,  9, 21,  4,  7, 20,  7, 22,  4, 11,  5, 13,  4,  5,\n",
       "         22,  5, 12,  4, 10,  6,  4, 10, 12,  4, 17,  5, 13,  6,  7, 10,  9, 15,\n",
       "         22,  4, 27,  5, 13, 22,  4, 15, 10, 28,  5,  4,  6, 11,  5,  4,  8, 15,\n",
       "         14,  4, 24,  8, 13,  6, 13,  7, 10,  6,  2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the processor to get back an array of token IDs\n",
    "tts_inputs = tts_processor(text=output_text, return_tensors=\"pt\");\n",
    "tts_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb903550",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_input_token_ids = tts_inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b39a3522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cmu-arctic-xvectors (/Users/iskander/.cache/huggingface/datasets/Matthijs___cmu-arctic-xvectors/default/0.0.1/a62fea1f9415e240301ea0042ffad2a3aadf4d1caa7f9a8d9512d631723e781f)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load vector describing speaker voice\n",
    "speaker_embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embeddings = torch.tensor(speaker_embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
    "\n",
    "# get a vocoder model to generate final sound\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c72518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the TTS model, a speaker embedding, and vocoder to actually generate sounds for the \n",
    "# text token IDs\n",
    "output_speech = tts_model.generate_speech(tts_input_token_ids, speaker_embeddings, vocoder=vocoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8096adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sound file \n",
    "import soundfile as sf\n",
    "sf.write(\"round-trip-output.wav\", output_speech.numpy(), samplerate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f029e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpleaudio \n",
    "import numpy as np\n",
    "\n",
    "def normalize_waveform(single_channel_float_waveform, min_int=-32768, max_int=32767, output_dtype=np.int16):\n",
    "    # simpleaudio expects 16-bit integer values for wave height\n",
    "    # so normalize float sound arrays to fit that range\n",
    "    int_range = max_int - min_int\n",
    "    normalized_waveform = single_channel_float_waveform - single_channel_float_waveform.min()\n",
    "    normalized_waveform /= normalized_waveform.max()\n",
    "    int64_waveform_from_0 = (normalized_waveform * int_range).astype(np.int64)\n",
    "    int64_waveform_from_min = int64_waveform_from_0 + min_int\n",
    "    return int64_waveform_from_min.astype(output_dtype)\n",
    "    \n",
    "def play(single_channel_float_waveform, num_channels=1, bytes_per_sample=2, sampling_rate=16000):\n",
    "    int_waveform = normalize_waveform(single_channel_float_waveform)\n",
    "    play_obj = simpleaudio.play_buffer(int_waveform, num_channels, bytes_per_sample, sampling_rate)\n",
    "    # wait for play-back to finish\n",
    "    play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5f923e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "play(input_sound, sampling_rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efe6fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "play(output_speech.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
