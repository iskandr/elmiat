{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5787df2c",
   "metadata": {},
   "source": [
    "Following HuggingFace SpeechT5 tutorial to combine ASR and TTS (https://huggingface.co/blog/speecht5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b245567",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch\n",
    "!pip install -q sentencepiece\n",
    "!pip install -q torchaudio \n",
    "!pip install -q transformers\n",
    "!pip install -q soundfile\n",
    "\n",
    "# there's probably a better library for playing audio \n",
    "!pip install -q simpleaudio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82060322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2086-149220-0033.wav\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898d727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an example sound file\n",
    "\n",
    "import soundfile as sf\n",
    "# returns a tuple of (NumPy array of the waveform, sampling rate)\n",
    "input_sound_tuple = sf.read(\"../data/2086-149220-0033.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d9d4c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00000000e+00, 9.15527344e-05, 9.15527344e-05, ...,\n",
       "        1.22070312e-04, 1.22070312e-04, 1.22070312e-04]),\n",
       " 16000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sound_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b752bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sound, sampling_rate = input_sound_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b081287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iskander/miniconda3/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "asr = pipeline(task=\"automatic-speech-recognition\", model=\"microsoft/speecht5_asr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89eee4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iskander/miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1349: UserWarning: Using `max_length`'s default (450) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# get back a text transcription from the sound\n",
    "asr_result = asr(input_sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06b5ac7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"well i don't wish to see it any more observed febric turning away her eyes it is certainly very like the old portrait\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's dictionary with a single field called 'text'\n",
    "asr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b19d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = asr_result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f164b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech\n",
    "\n",
    "# the text-to-speech model has two parts: a tokenizer/processor which turns the character stream into \n",
    "# a matrix of token IDs and an actual speech synthesizer\n",
    "tts_processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "tts_model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed89be94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 4, 20,  5, 15, 15,  4, 10,  4, 14,  8,  9, 31,  6,  4, 20, 10, 12, 11,\n",
       "          4,  6,  8,  4, 12,  5,  5,  4, 10,  6,  4,  7,  9, 22,  4, 18,  8, 13,\n",
       "          5,  4,  8, 25, 12,  5, 13, 27,  5, 14,  4, 19,  5, 25, 13, 10, 17,  4,\n",
       "          6, 16, 13,  9, 10,  9, 21,  4,  7, 20,  7, 22,  4, 11,  5, 13,  4,  5,\n",
       "         22,  5, 12,  4, 10,  6,  4, 10, 12,  4, 17,  5, 13,  6,  7, 10,  9, 15,\n",
       "         22,  4, 27,  5, 13, 22,  4, 15, 10, 28,  5,  4,  6, 11,  5,  4,  8, 15,\n",
       "         14,  4, 24,  8, 13,  6, 13,  7, 10,  6,  2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the processor to get back an array of token IDs\n",
    "tts_inputs = tts_processor(text=text, return_tensors=\"pt\");\n",
    "tts_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb903550",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_input_token_ids = tts_inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b39a3522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cmu-arctic-xvectors (/Users/iskander/.cache/huggingface/datasets/Matthijs___cmu-arctic-xvectors/default/0.0.1/a62fea1f9415e240301ea0042ffad2a3aadf4d1caa7f9a8d9512d631723e781f)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load vector describing speaker voice\n",
    "speaker_embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embeddings = torch.tensor(speaker_embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
    "\n",
    "# get a vocoder model to generate final sound\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c72518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the TTS model, a speaker embedding, and vocoder to actually generate sounds for the \n",
    "# text token IDs\n",
    "output_speech = tts_model.generate_speech(tts_input_token_ids, speaker_embeddings, vocoder=vocoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8096adfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sound file \n",
    "import soundfile as sf\n",
    "sf.write(\"round-trip-output.wav\", output_speech.numpy(), samplerate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f029e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpleaudio \n",
    "import numpy as np\n",
    "\n",
    "def normalize_waveform(single_channel_float_waveform, min_int=-32768, max_int=32767, output_dtype=np.int16):\n",
    "    # simpleaudio expects 16-bit integer values for wave height\n",
    "    # so normalize float sound arrays to fit that range\n",
    "    int_range = max_int - min_int\n",
    "    normalized_waveform = single_channel_float_waveform - single_channel_float_waveform.min()\n",
    "    normalized_waveform /= normalized_waveform.max()\n",
    "    int64_waveform_from_0 = (normalized_waveform * int_range).astype(np.int64)\n",
    "    int64_waveform_from_min = int64_waveform_from_0 + min_int\n",
    "    return int64_waveform_from_min.astype(output_dtype)\n",
    "    \n",
    "def play(single_channel_float_waveform, num_channels=1, bytes_per_sample=2, sampling_rate=16000):\n",
    "    int_waveform = normalize_waveform(single_channel_float_waveform)\n",
    "    play_obj = simpleaudio.play_buffer(int_waveform, num_channels, bytes_per_sample, sampling_rate)\n",
    "    # wait for play-back to finish\n",
    "    play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5f923e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "play(input_sound, sampling_rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efe6fe3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "play(output_speech.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
