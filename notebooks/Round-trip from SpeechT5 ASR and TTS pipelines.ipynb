{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80536db5",
   "metadata": {},
   "source": [
    "Following HuggingFace SpeechT5 tutorial to combine ASR and TTS (https://huggingface.co/blog/speecht5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch\n",
    "!pip install -q sentencepiece\n",
    "!pip install -q torchaudio \n",
    "!pip install -q transformers\n",
    "!pip install -q soundfile\n",
    "\n",
    "# there's probably a better library for playing audio \n",
    "!pip install -q simpleaudio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68672df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29f3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load an example sound file\n",
    "\n",
    "import soundfile as sf\n",
    "# returns a tuple of (NumPy array of the waveform, sampling rate)\n",
    "input_sound_tuple = sf.read(\"../data/2086-149220-0033.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6591ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sound_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038ef9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sound, sampling_rate = input_sound_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7196649e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iskander/miniconda3/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "asr = pipeline(task=\"automatic-speech-recognition\", model=\"microsoft/speecht5_asr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b998b248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iskander/miniconda3/lib/python3.10/site-packages/transformers/generation/utils.py:1349: UserWarning: Using `max_length`'s default (450) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# get back a text transcription from the sound\n",
    "asr_result = asr(input_sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4e16d6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"well i don't wish to see it any more observed febric turning away her eyes it is certainly very like the old portrait\"}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's dictionary with a single field called 'text'\n",
    "asr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39815fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = asr_result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3670f4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 4, 20,  5, 15, 15,  4, 10,  4, 14,  8,  9, 31,  6,  4, 20, 10, 12, 11,\n",
       "          4,  6,  8,  4, 12,  5,  5,  4, 10,  6,  4,  7,  9, 22,  4, 18,  8, 13,\n",
       "          5,  4,  8, 25, 12,  5, 13, 27,  5, 14,  4, 19,  5, 25, 13, 10, 17,  4,\n",
       "          6, 16, 13,  9, 10,  9, 21,  4,  7, 20,  7, 22,  4, 11,  5, 13,  4,  5,\n",
       "         22,  5, 12,  4, 10,  6,  4, 10, 12,  4, 17,  5, 13,  6,  7, 10,  9, 15,\n",
       "         22,  4, 27,  5, 13, 22,  4, 15, 10, 28,  5,  4,  6, 11,  5,  4,  8, 15,\n",
       "         14,  4, 24,  8, 13,  6, 13,  7, 10,  6,  2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech\n",
    "\n",
    "# the text-to-speech model has two parts: a tokenizer/processor which turns the character stream into \n",
    "# a matrix of token IDs and an actual speech synthesizer\n",
    "tts_processor = SpeechT5Processor.from_pretrained(\"microsoft/speecht5_tts\")\n",
    "tts_model = SpeechT5ForTextToSpeech.from_pretrained(\"microsoft/speecht5_tts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fa9f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the processor to get back an array of token IDs\n",
    "tts_inputs = tts_processor(text=text, return_tensors=\"pt\");\n",
    "tts_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2dae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "tts_input_token_ids = tts_inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "872c1213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cmu-arctic-xvectors (/Users/iskander/.cache/huggingface/datasets/Matthijs___cmu-arctic-xvectors/default/0.0.1/a62fea1f9415e240301ea0042ffad2a3aadf4d1caa7f9a8d9512d631723e781f)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import SpeechT5HifiGan\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load vector describing speaker voice\n",
    "speaker_embeddings_dataset = load_dataset(\"Matthijs/cmu-arctic-xvectors\", split=\"validation\")\n",
    "speaker_embeddings = torch.tensor(speaker_embeddings_dataset[7306][\"xvector\"]).unsqueeze(0)\n",
    "\n",
    "# get a vocoder model to generate final sound\n",
    "vocoder = SpeechT5HifiGan.from_pretrained(\"microsoft/speecht5_hifigan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de19198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the TTS model, a speaker embedding, and vocoder to actually generate sounds for the \n",
    "# text token IDs\n",
    "output_speech = tts_model.generate_speech(tts_input_token_ids, speaker_embeddings, vocoder=vocoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7370934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the sound file \n",
    "import soundfile as sf\n",
    "sf.write(\"round-trip-output.wav\", output_speech.numpy(), samplerate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "99511513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpleaudio \n",
    "import numpy as np\n",
    "\n",
    "def normalize_waveform(single_channel_float_waveform, min_int=-32768, max_int=32767, output_dtype=np.int16)\n",
    "    # simpleaudio expects 16-bit integer values for wave height\n",
    "    # so normalize float sound arrays to fit that range\n",
    "    int_range = max_int - min_int\n",
    "    normalized_waveform = single_channel_float_waveform - single_channel_float_waveform.min()\n",
    "    normalized_waveform /= normalized_waveform.max()\n",
    "    int64_waveform_from_0 = (normalized_waveform * int_range).astype(np.int64)\n",
    "    int64_waveform_from_min = int64_waveform_from_0 + min_int\n",
    "    return int64_waveform_from_min.astype(output_dtype)\n",
    "    \n",
    "def play(single_channel_float_waveform, num_channels=1, bytes_per_sample=2, sampling_rate=16000):\n",
    "    int_waveform = normalize_waveform(single_channel_float_waveform)\n",
    "    play_obj = simpleaudio.play_buffer(int_waveform, num_channel, bytes_per_sample, sampling_rate)\n",
    "    # wait for play-back to finish\n",
    "    play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ab2c827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "play(input_sound, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "da6f60d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "play(output_speech.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993ff5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2a3478",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
